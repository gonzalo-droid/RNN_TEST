{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import plotly \n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "#import twitter data\n",
    "filename = '../Data/Tweets.csv'\n",
    "dataset = pd.read_csv(filename)\n",
    "print(dataset.shape)#rows x columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cantidad de tweet por clase\n",
    "dataset['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir a entero los valores de las clases\n",
    "dataset['airline_sentiment'] = dataset['airline_sentiment'].replace('neutral', 1)\n",
    "dataset['airline_sentiment'] = dataset['airline_sentiment'].replace('negative', 0)\n",
    "dataset['airline_sentiment'] = dataset['airline_sentiment'].replace('positive', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividar los datos entre text y clase\n",
    "X = dataset['text'] # data\n",
    "y = dataset['airline_sentiment'] # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Procesando Datos<7h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer  #reemplazar los caracteres especiales\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence #analiza la secuencia de los caracteres\n",
    "# Convertisa los datos en token\n",
    "# create tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(X)\n",
    "# Encuentra la cantidad de palabras únicas en los tweets\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# indexar las palabras (relacionar con su par entero)\n",
    "sequences = t.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor numero de caracteres en un tweet  30\n"
     ]
    }
   ],
   "source": [
    "# Encuentra el tweet con mayor numero de caracteres para ser tomado como referencias \n",
    "#al momento de vectorizar a las palabras\n",
    "def max_tweet():\n",
    "    for i in range(1, len(sequences)):\n",
    "        max_length = len(sequences[0])\n",
    "        if len(sequences[i]) > max_length:\n",
    "            max_length = len(sequences[i])\n",
    "    return max_length\n",
    "tweet_num = max_tweet()\n",
    "print(\"Mayor numero de caracteres en un tweet \" , tweet_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  81,   62, 6686, ...,    0,    0,    0],\n",
       "       [  81,  558,  590, ...,    0,    0,    0],\n",
       "       [  81,    3,  207, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  13,   75,  661, ...,    0,    0,    0],\n",
       "       [  13,    6,   22, ...,    0,    0,    0],\n",
       "       [  13,   41,   22, ...,    2,  179,    8]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# las palabras no encontradas en el tweet se llenan con ceros en el array\n",
    "# https://realpython.com/python-keras-text-classification/\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = tweet_num\n",
    "padded_X = pad_sequences(sequences, padding='post', maxlen=maxlen)\n",
    "valor_maximo =np.amax(padded_X) \n",
    "padded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convertir las etiquestas\n",
    "labels = to_categorical(np.asarray(y))\n",
    "labels\n",
    "# 1 => representa la clase que representa negativo / neutral / positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "padded_Y = array[:,1] #array de clases\n",
    "padded_Y_test=padded_Y.astype('int')\n",
    "#padded_Y\n",
    "padded_X_test = (padded_X /valor_maximo) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size: (11712, 30)\n",
      "y_train size: (11712, 3)\n",
      "X_test size: (2928, 30)\n",
      "y_test size: (2928, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_X, labels, test_size = 0.2, random_state = 0)\n",
    "# Size of train and test datasets\n",
    "print('X_train size:', X_train.shape)\n",
    "print('y_train size:', y_train.shape)\n",
    "print('X_test size:', X_test.shape)\n",
    "print('y_test size:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectores de palabras cargados: 400000\n"
     ]
    }
   ],
   "source": [
    "# GloVe se define como un “algoritmo de aprendizaje no supervisado \n",
    "#para obtener representaciones vectoriales de palabras”. \n",
    "#Descargamos datos del sitio web vinculado y usamos específicamente las incrustaciones\n",
    "#100-dimensionales de 400k palabras de Wikipedia en inglés en 2014. \n",
    "#Esto se representa en un archivo txt que debemos analizar para crear un\n",
    "#índice que mapee las palabras a su representación vectorial.\n",
    "\n",
    "# 100 dimensional version (embedding dimension)\n",
    "\n",
    "#ayuda a en la decodificacion\n",
    "#https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character\n",
    "embeddings_index = dict()\n",
    "f = open('../Data/glove/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Vectores de palabras cargados: %s' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15769, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se Obtiene todas las palabras únicas en nuestro conjunto de entrenamiento: índice de tokenizadores\n",
    "# Se encuentra el vector de peso correspondiente en la incrustación de GloVe\n",
    "\n",
    "# Se define el tamaño de la matriz de incrustación: número de palabras únicas x incrustación dim (100)\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "\n",
    "# llenado de la matrix\n",
    "for word, i in t.word_index.items():  # dictionary\n",
    "    embedding_vector = embeddings_index.get(word) # obtiene un vector incrustado de palabra de GloVe\n",
    "    if embedding_vector is not None:\n",
    "        # se agrega a la matrix\n",
    "        embedding_matrix[i] = embedding_vector # cada fila de la matrix\n",
    "\n",
    "#print(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una capa de incrustación usando una matriz de incrustación\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# la entrada es vocab_size, la salida es 100\n",
    "# pesos de la matriz de incrustación, establezca entrenable = Falso || para q no se modifiquen los valores de Glove\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix],\n",
    "                           input_length = tweet_num, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Simple LSTM Model with regularization, increase dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1576900   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               365568    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 1,943,239\n",
      "Trainable params: 366,339\n",
      "Non-trainable params: 1,576,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_mod1 = Sequential()\n",
    "lstm_mod1.add(embedding_layer)\n",
    "lstm_mod1.add(LSTM(256, \n",
    "               dropout = 0.2, \n",
    "               recurrent_dropout = 0.5))\n",
    "lstm_mod1.add(Dense(3, activation='softmax'))\n",
    "lstm_mod1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "lstm_mod1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 17s 447ms/step - loss: 0.8293 - acc: 0.6407 - val_loss: 0.7364 - val_acc: 0.6876\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 16s 432ms/step - loss: 0.7038 - acc: 0.7113 - val_loss: 0.6342 - val_acc: 0.7418\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 17s 449ms/step - loss: 0.6420 - acc: 0.7362 - val_loss: 0.6004 - val_acc: 0.7559\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 16s 441ms/step - loss: 0.6178 - acc: 0.7481 - val_loss: 0.5858 - val_acc: 0.7495\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 16s 445ms/step - loss: 0.6037 - acc: 0.7543 - val_loss: 0.5757 - val_acc: 0.7717\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 17s 455ms/step - loss: 0.5857 - acc: 0.7607 - val_loss: 0.5631 - val_acc: 0.7678\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 17s 450ms/step - loss: 0.5718 - acc: 0.7701 - val_loss: 0.5572 - val_acc: 0.7734\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 21s 562ms/step - loss: 0.5572 - acc: 0.7760 - val_loss: 0.5407 - val_acc: 0.7951\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 19s 508ms/step - loss: 0.5385 - acc: 0.7806 - val_loss: 0.5557 - val_acc: 0.7875\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 18s 493ms/step - loss: 0.5337 - acc: 0.7857 - val_loss: 0.5317 - val_acc: 0.7879\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 18s 485ms/step - loss: 0.5216 - acc: 0.7907 - val_loss: 0.5490 - val_acc: 0.7853\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 18s 481ms/step - loss: 0.5063 - acc: 0.7985 - val_loss: 0.5659 - val_acc: 0.7751\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 17s 455ms/step - loss: 0.5116 - acc: 0.7917 - val_loss: 0.5363 - val_acc: 0.7836\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 17s 448ms/step - loss: 0.4873 - acc: 0.8024 - val_loss: 0.5596 - val_acc: 0.7887\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 17s 448ms/step - loss: 0.4725 - acc: 0.8113 - val_loss: 0.5425 - val_acc: 0.7930\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 17s 453ms/step - loss: 0.4755 - acc: 0.8088 - val_loss: 0.5180 - val_acc: 0.8020\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 17s 453ms/step - loss: 0.4543 - acc: 0.8175 - val_loss: 0.5339 - val_acc: 0.7887\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 17s 464ms/step - loss: 0.4517 - acc: 0.8163 - val_loss: 0.5248 - val_acc: 0.7930\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 17s 454ms/step - loss: 0.4391 - acc: 0.8254 - val_loss: 0.5397 - val_acc: 0.8003\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 17s 451ms/step - loss: 0.4297 - acc: 0.8273 - val_loss: 0.5352 - val_acc: 0.8015\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 17s 448ms/step - loss: 0.4246 - acc: 0.8271 - val_loss: 0.5419 - val_acc: 0.7973\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 17s 452ms/step - loss: 0.4304 - acc: 0.8262 - val_loss: 0.5300 - val_acc: 0.7956\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 17s 450ms/step - loss: 0.4079 - acc: 0.8356 - val_loss: 0.5561 - val_acc: 0.7981\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 18s 474ms/step - loss: 0.3992 - acc: 0.8426 - val_loss: 0.5345 - val_acc: 0.8003\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 17s 469ms/step - loss: 0.3984 - acc: 0.8428 - val_loss: 0.5671 - val_acc: 0.7994\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 19s 523ms/step - loss: 0.3750 - acc: 0.8519 - val_loss: 0.5191 - val_acc: 0.8007\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 19s 509ms/step - loss: 0.3673 - acc: 0.8524 - val_loss: 0.5487 - val_acc: 0.8045\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 18s 476ms/step - loss: 0.3658 - acc: 0.8576 - val_loss: 0.5697 - val_acc: 0.8032\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 19s 516ms/step - loss: 0.3582 - acc: 0.8587 - val_loss: 0.5591 - val_acc: 0.7990\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 19s 516ms/step - loss: 0.3438 - acc: 0.8630 - val_loss: 0.5561 - val_acc: 0.7866\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 18s 494ms/step - loss: 0.3427 - acc: 0.8679 - val_loss: 0.5774 - val_acc: 0.7836\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 19s 523ms/step - loss: 0.3384 - acc: 0.8657 - val_loss: 0.5489 - val_acc: 0.8003\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 19s 509ms/step - loss: 0.3132 - acc: 0.8725 - val_loss: 0.6138 - val_acc: 0.8041\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 17s 473ms/step - loss: 0.3190 - acc: 0.8763 - val_loss: 0.5813 - val_acc: 0.7960\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 18s 483ms/step - loss: 0.3074 - acc: 0.8817 - val_loss: 0.6321 - val_acc: 0.7960\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 19s 508ms/step - loss: 0.2889 - acc: 0.8884 - val_loss: 0.6433 - val_acc: 0.7939\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 19s 517ms/step - loss: 0.2963 - acc: 0.8821 - val_loss: 0.6220 - val_acc: 0.7964\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 18s 499ms/step - loss: 0.2711 - acc: 0.8973 - val_loss: 0.6134 - val_acc: 0.8032\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 18s 474ms/step - loss: 0.2728 - acc: 0.8964 - val_loss: 0.6519 - val_acc: 0.7994\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 18s 480ms/step - loss: 0.2648 - acc: 0.8966 - val_loss: 0.6493 - val_acc: 0.7849\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 18s 493ms/step - loss: 0.2551 - acc: 0.9031 - val_loss: 0.6547 - val_acc: 0.7964\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 17s 463ms/step - loss: 0.2605 - acc: 0.9007 - val_loss: 0.6757 - val_acc: 0.7981\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 18s 490ms/step - loss: 0.2518 - acc: 0.9015 - val_loss: 0.6621 - val_acc: 0.7900\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 20s 530ms/step - loss: 0.2405 - acc: 0.9078 - val_loss: 0.7033 - val_acc: 0.7947\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 19s 507ms/step - loss: 0.2307 - acc: 0.9126 - val_loss: 0.6579 - val_acc: 0.7934\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 18s 495ms/step - loss: 0.2224 - acc: 0.9160 - val_loss: 0.6718 - val_acc: 0.7939\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 19s 511ms/step - loss: 0.2264 - acc: 0.9155 - val_loss: 0.6625 - val_acc: 0.8020\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 19s 515ms/step - loss: 0.2019 - acc: 0.9257 - val_loss: 0.7389 - val_acc: 0.7943\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 18s 476ms/step - loss: 0.2020 - acc: 0.9222 - val_loss: 0.7440 - val_acc: 0.7909\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 17s 453ms/step - loss: 0.1930 - acc: 0.9286 - val_loss: 0.6927 - val_acc: 0.7930\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 17s 449ms/step - loss: 0.1865 - acc: 0.9308 - val_loss: 0.7599 - val_acc: 0.7943\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 17s 454ms/step - loss: 0.1829 - acc: 0.9312 - val_loss: 0.7790 - val_acc: 0.7926\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 17s 449ms/step - loss: 0.1843 - acc: 0.9316 - val_loss: 0.7606 - val_acc: 0.7896\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 17s 454ms/step - loss: 0.1749 - acc: 0.9368 - val_loss: 0.6984 - val_acc: 0.7977\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 17s 452ms/step - loss: 0.1795 - acc: 0.9310 - val_loss: 0.7553 - val_acc: 0.8003\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 17s 452ms/step - loss: 0.1606 - acc: 0.9398 - val_loss: 0.7680 - val_acc: 0.7875\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 18s 476ms/step - loss: 0.1616 - acc: 0.9393 - val_loss: 0.7992 - val_acc: 0.7917\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 20s 544ms/step - loss: 0.1599 - acc: 0.9402 - val_loss: 0.8581 - val_acc: 0.7921\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 21s 565ms/step - loss: 0.1546 - acc: 0.9407 - val_loss: 0.7597 - val_acc: 0.7947\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 23s 610ms/step - loss: 0.1486 - acc: 0.9473 - val_loss: 0.8401 - val_acc: 0.7994\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 22s 591ms/step - loss: 0.1453 - acc: 0.9448 - val_loss: 0.8838 - val_acc: 0.7934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "37/37 [==============================] - 22s 596ms/step - loss: 0.1410 - acc: 0.9492 - val_loss: 0.8321 - val_acc: 0.7904\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 19s 508ms/step - loss: 0.1321 - acc: 0.9523 - val_loss: 0.9258 - val_acc: 0.7943\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 20s 531ms/step - loss: 0.1374 - acc: 0.9503 - val_loss: 0.8371 - val_acc: 0.7887\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 19s 508ms/step - loss: 0.1299 - acc: 0.9515 - val_loss: 0.9188 - val_acc: 0.7943\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 19s 522ms/step - loss: 0.1386 - acc: 0.9489 - val_loss: 0.8985 - val_acc: 0.7828\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 18s 480ms/step - loss: 0.1282 - acc: 0.9516 - val_loss: 0.8792 - val_acc: 0.7956\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 17s 447ms/step - loss: 0.1249 - acc: 0.9533 - val_loss: 0.8866 - val_acc: 0.7939\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 17s 447ms/step - loss: 0.1272 - acc: 0.9533 - val_loss: 0.9261 - val_acc: 0.7913\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 17s 447ms/step - loss: 0.1104 - acc: 0.9594 - val_loss: 0.9355 - val_acc: 0.7913\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 17s 449ms/step - loss: 0.1169 - acc: 0.9566 - val_loss: 0.9644 - val_acc: 0.7913\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 18s 493ms/step - loss: 0.0989 - acc: 0.9667 - val_loss: 0.9938 - val_acc: 0.7789\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 19s 516ms/step - loss: 0.1143 - acc: 0.9606 - val_loss: 0.9930 - val_acc: 0.7823\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 21s 564ms/step - loss: 0.1131 - acc: 0.9607 - val_loss: 0.9550 - val_acc: 0.7832\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 21s 556ms/step - loss: 0.1092 - acc: 0.9619 - val_loss: 0.9441 - val_acc: 0.7845\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 19s 523ms/step - loss: 0.1071 - acc: 0.9623 - val_loss: 0.8583 - val_acc: 0.7892\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 19s 502ms/step - loss: 0.1031 - acc: 0.9644 - val_loss: 1.0161 - val_acc: 0.7930\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 17s 458ms/step - loss: 0.1049 - acc: 0.9640 - val_loss: 0.9652 - val_acc: 0.7862\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 17s 461ms/step - loss: 0.0851 - acc: 0.9717 - val_loss: 1.0812 - val_acc: 0.7845\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 17s 463ms/step - loss: 0.1031 - acc: 0.9662 - val_loss: 0.9220 - val_acc: 0.7900\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 17s 462ms/step - loss: 0.0968 - acc: 0.9650 - val_loss: 1.0157 - val_acc: 0.7904\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 16s 444ms/step - loss: 0.0926 - acc: 0.9671 - val_loss: 0.9709 - val_acc: 0.7985\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 16s 446ms/step - loss: 0.0876 - acc: 0.9692 - val_loss: 0.9759 - val_acc: 0.7815\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 16s 437ms/step - loss: 0.0887 - acc: 0.9683 - val_loss: 0.9860 - val_acc: 0.7862\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 16s 436ms/step - loss: 0.0858 - acc: 0.9685 - val_loss: 0.9938 - val_acc: 0.7900\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 17s 447ms/step - loss: 0.0884 - acc: 0.9686 - val_loss: 0.9458 - val_acc: 0.7956\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 16s 443ms/step - loss: 0.0947 - acc: 0.9667 - val_loss: 0.9599 - val_acc: 0.7836\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 16s 444ms/step - loss: 0.0818 - acc: 0.9714 - val_loss: 1.0070 - val_acc: 0.7960\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 16s 439ms/step - loss: 0.0757 - acc: 0.9759 - val_loss: 1.0585 - val_acc: 0.7998\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 17s 451ms/step - loss: 0.0767 - acc: 0.9724 - val_loss: 1.0520 - val_acc: 0.7875\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 17s 458ms/step - loss: 0.0843 - acc: 0.9690 - val_loss: 1.0228 - val_acc: 0.7951\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 17s 470ms/step - loss: 0.0765 - acc: 0.9727 - val_loss: 1.0557 - val_acc: 0.7866\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 18s 482ms/step - loss: 0.0755 - acc: 0.9746 - val_loss: 1.0492 - val_acc: 0.7921\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 17s 472ms/step - loss: 0.0714 - acc: 0.9735 - val_loss: 1.0307 - val_acc: 0.7875\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 17s 455ms/step - loss: 0.0810 - acc: 0.9720 - val_loss: 0.9988 - val_acc: 0.7879\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 17s 446ms/step - loss: 0.0730 - acc: 0.9741 - val_loss: 1.0767 - val_acc: 0.7930\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 17s 458ms/step - loss: 0.0747 - acc: 0.9736 - val_loss: 1.0490 - val_acc: 0.7977\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 17s 457ms/step - loss: 0.0830 - acc: 0.9701 - val_loss: 0.9750 - val_acc: 0.7990\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 17s 456ms/step - loss: 0.0665 - acc: 0.9773 - val_loss: 1.1089 - val_acc: 0.7776\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 17s 457ms/step - loss: 0.0712 - acc: 0.9745 - val_loss: 1.0458 - val_acc: 0.7866\n"
     ]
    }
   ],
   "source": [
    "hist_1 = lstm_mod1.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9530\n",
      "Testing Accuracy:  0.7722\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento y test accuracy\n",
    "loss, accuracy = lstm_mod1.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = lstm_mod1.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM with regularization, reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1576900   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,619,335\n",
      "Trainable params: 42,435\n",
      "Non-trainable params: 1,576,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_mod2 = Sequential()\n",
    "lstm_mod2.add(embedding_layer)\n",
    "lstm_mod2.add(LSTM(64, \n",
    "               dropout = 0.2, \n",
    "               recurrent_dropout = 0.5))\n",
    "lstm_mod2.add(Dense(3, activation='softmax'))\n",
    "lstm_mod2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "lstm_mod2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 5s 146ms/step - loss: 0.8854 - acc: 0.6087 - val_loss: 0.8396 - val_acc: 0.6176\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 4s 112ms/step - loss: 0.8107 - acc: 0.6486 - val_loss: 0.7606 - val_acc: 0.7008\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 4s 117ms/step - loss: 0.7197 - acc: 0.7104 - val_loss: 0.6868 - val_acc: 0.7345\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.6623 - acc: 0.7313 - val_loss: 0.6176 - val_acc: 0.7567\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 4s 114ms/step - loss: 0.6369 - acc: 0.7464 - val_loss: 0.6287 - val_acc: 0.7580\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.6214 - acc: 0.7465 - val_loss: 0.5880 - val_acc: 0.7682\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 4s 103ms/step - loss: 0.5961 - acc: 0.7548 - val_loss: 0.5728 - val_acc: 0.7682\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 4s 106ms/step - loss: 0.5807 - acc: 0.7656 - val_loss: 0.5719 - val_acc: 0.7772\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 4s 115ms/step - loss: 0.5816 - acc: 0.7608 - val_loss: 0.5551 - val_acc: 0.7751\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.5722 - acc: 0.7701 - val_loss: 0.5470 - val_acc: 0.7798\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 4s 103ms/step - loss: 0.5582 - acc: 0.7769 - val_loss: 0.5435 - val_acc: 0.7904\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 4s 108ms/step - loss: 0.5481 - acc: 0.7834 - val_loss: 0.5329 - val_acc: 0.7866\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.5345 - acc: 0.7873 - val_loss: 0.5328 - val_acc: 0.7900\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.5294 - acc: 0.7854 - val_loss: 0.5243 - val_acc: 0.7994\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.5227 - acc: 0.7865 - val_loss: 0.5516 - val_acc: 0.7892\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.5228 - acc: 0.7883 - val_loss: 0.5285 - val_acc: 0.7913\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 4s 112ms/step - loss: 0.5126 - acc: 0.7956 - val_loss: 0.5284 - val_acc: 0.7921\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 4s 107ms/step - loss: 0.5023 - acc: 0.7988 - val_loss: 0.5160 - val_acc: 0.7990\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.4994 - acc: 0.7994 - val_loss: 0.5274 - val_acc: 0.8067\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 4s 107ms/step - loss: 0.4873 - acc: 0.8041 - val_loss: 0.5256 - val_acc: 0.7964\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 5s 122ms/step - loss: 0.4873 - acc: 0.8031 - val_loss: 0.5102 - val_acc: 0.7985\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 4s 106ms/step - loss: 0.4734 - acc: 0.8133 - val_loss: 0.5183 - val_acc: 0.7943\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.4793 - acc: 0.8077 - val_loss: 0.5223 - val_acc: 0.7956\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.4735 - acc: 0.8111 - val_loss: 0.5126 - val_acc: 0.8088\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.4647 - acc: 0.8141 - val_loss: 0.5078 - val_acc: 0.8096\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.4684 - acc: 0.8145 - val_loss: 0.5158 - val_acc: 0.8041\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.4591 - acc: 0.8174 - val_loss: 0.5062 - val_acc: 0.7973\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.4484 - acc: 0.8197 - val_loss: 0.5007 - val_acc: 0.8101\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.4460 - acc: 0.8235 - val_loss: 0.5108 - val_acc: 0.7956\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.4468 - acc: 0.8232 - val_loss: 0.5189 - val_acc: 0.8079\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.4350 - acc: 0.8270 - val_loss: 0.5139 - val_acc: 0.8058\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.4348 - acc: 0.8263 - val_loss: 0.5060 - val_acc: 0.8024\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.4413 - acc: 0.8242 - val_loss: 0.5269 - val_acc: 0.8067\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.4366 - acc: 0.8298 - val_loss: 0.5265 - val_acc: 0.8071\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 4s 106ms/step - loss: 0.4152 - acc: 0.8321 - val_loss: 0.5256 - val_acc: 0.8071\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.4242 - acc: 0.8305 - val_loss: 0.5082 - val_acc: 0.7985\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.4228 - acc: 0.8298 - val_loss: 0.5115 - val_acc: 0.8067\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.4080 - acc: 0.8379 - val_loss: 0.5311 - val_acc: 0.8079\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 4s 107ms/step - loss: 0.4115 - acc: 0.8374 - val_loss: 0.5246 - val_acc: 0.7981\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 4s 112ms/step - loss: 0.3991 - acc: 0.8464 - val_loss: 0.5275 - val_acc: 0.8011\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.3973 - acc: 0.8411 - val_loss: 0.5219 - val_acc: 0.8020\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 4s 104ms/step - loss: 0.4112 - acc: 0.8361 - val_loss: 0.5149 - val_acc: 0.8088\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.4002 - acc: 0.8406 - val_loss: 0.5564 - val_acc: 0.8032\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 4s 112ms/step - loss: 0.3936 - acc: 0.8426 - val_loss: 0.5202 - val_acc: 0.7964\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.3878 - acc: 0.8486 - val_loss: 0.5541 - val_acc: 0.7793\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 4s 100ms/step - loss: 0.3964 - acc: 0.8451 - val_loss: 0.5121 - val_acc: 0.8096\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 4s 108ms/step - loss: 0.3846 - acc: 0.8481 - val_loss: 0.5282 - val_acc: 0.8003\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 4s 115ms/step - loss: 0.3849 - acc: 0.8475 - val_loss: 0.5331 - val_acc: 0.8084\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.3843 - acc: 0.8483 - val_loss: 0.5317 - val_acc: 0.7977\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 4s 107ms/step - loss: 0.3734 - acc: 0.8516 - val_loss: 0.5556 - val_acc: 0.8075\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 4s 108ms/step - loss: 0.3729 - acc: 0.8510 - val_loss: 0.5441 - val_acc: 0.8101\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 4s 112ms/step - loss: 0.3687 - acc: 0.8532 - val_loss: 0.5508 - val_acc: 0.8114\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 4s 108ms/step - loss: 0.3621 - acc: 0.8586 - val_loss: 0.5653 - val_acc: 0.7964\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 4s 106ms/step - loss: 0.3722 - acc: 0.8546 - val_loss: 0.5637 - val_acc: 0.8054\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.3514 - acc: 0.8633 - val_loss: 0.5408 - val_acc: 0.7981\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.3582 - acc: 0.8562 - val_loss: 0.5703 - val_acc: 0.8028\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.3650 - acc: 0.8572 - val_loss: 0.5614 - val_acc: 0.7900\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 4s 105ms/step - loss: 0.3537 - acc: 0.8589 - val_loss: 0.5725 - val_acc: 0.8050\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 4s 107ms/step - loss: 0.3546 - acc: 0.8630 - val_loss: 0.5447 - val_acc: 0.7956\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 4s 115ms/step - loss: 0.3432 - acc: 0.8663 - val_loss: 0.5618 - val_acc: 0.8032\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.3431 - acc: 0.8656 - val_loss: 0.5584 - val_acc: 0.8011\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 4s 112ms/step - loss: 0.3420 - acc: 0.8630 - val_loss: 0.5757 - val_acc: 0.8058\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 5s 126ms/step - loss: 0.3363 - acc: 0.8691 - val_loss: 0.5710 - val_acc: 0.8011\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 5s 141ms/step - loss: 0.3374 - acc: 0.8705 - val_loss: 0.5463 - val_acc: 0.8075\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 4s 121ms/step - loss: 0.3324 - acc: 0.8685 - val_loss: 0.5750 - val_acc: 0.8058\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 4s 122ms/step - loss: 0.3293 - acc: 0.8709 - val_loss: 0.5586 - val_acc: 0.8015\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 5s 127ms/step - loss: 0.3315 - acc: 0.8672 - val_loss: 0.5673 - val_acc: 0.7981\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 5s 123ms/step - loss: 0.3263 - acc: 0.8692 - val_loss: 0.5844 - val_acc: 0.8054\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 4s 118ms/step - loss: 0.3209 - acc: 0.8768 - val_loss: 0.5773 - val_acc: 0.8071\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 4s 120ms/step - loss: 0.3286 - acc: 0.8718 - val_loss: 0.5787 - val_acc: 0.8020\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 4s 120ms/step - loss: 0.3301 - acc: 0.8720 - val_loss: 0.5785 - val_acc: 0.7875\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 4s 116ms/step - loss: 0.3271 - acc: 0.8715 - val_loss: 0.5950 - val_acc: 0.8032\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.3185 - acc: 0.8783 - val_loss: 0.5810 - val_acc: 0.8037\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 0.3104 - acc: 0.8779 - val_loss: 0.5884 - val_acc: 0.8032\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 6s 173ms/step - loss: 0.3075 - acc: 0.8796 - val_loss: 0.6022 - val_acc: 0.7998\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 5s 132ms/step - loss: 0.3044 - acc: 0.8790 - val_loss: 0.6027 - val_acc: 0.8050\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 5s 136ms/step - loss: 0.3097 - acc: 0.8807 - val_loss: 0.6019 - val_acc: 0.8062\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 6s 157ms/step - loss: 0.3028 - acc: 0.8795 - val_loss: 0.5938 - val_acc: 0.8050\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 5s 135ms/step - loss: 0.3035 - acc: 0.8832 - val_loss: 0.6120 - val_acc: 0.8058\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 5s 123ms/step - loss: 0.3045 - acc: 0.8814 - val_loss: 0.5959 - val_acc: 0.8041\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 4s 120ms/step - loss: 0.2942 - acc: 0.8870 - val_loss: 0.6293 - val_acc: 0.8037\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.2966 - acc: 0.8817 - val_loss: 0.6194 - val_acc: 0.8032\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 4s 119ms/step - loss: 0.2920 - acc: 0.8857 - val_loss: 0.5992 - val_acc: 0.8062\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.2887 - acc: 0.8832 - val_loss: 0.6175 - val_acc: 0.7960\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.2949 - acc: 0.8854 - val_loss: 0.6330 - val_acc: 0.7934\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 4s 119ms/step - loss: 0.2942 - acc: 0.8852 - val_loss: 0.6015 - val_acc: 0.8028\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 4s 118ms/step - loss: 0.2901 - acc: 0.8880 - val_loss: 0.6344 - val_acc: 0.8050\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 4s 116ms/step - loss: 0.2821 - acc: 0.8915 - val_loss: 0.6501 - val_acc: 0.8041\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.2877 - acc: 0.8852 - val_loss: 0.6471 - val_acc: 0.8032\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 4s 119ms/step - loss: 0.2834 - acc: 0.8909 - val_loss: 0.6286 - val_acc: 0.7998\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 4s 119ms/step - loss: 0.2869 - acc: 0.8865 - val_loss: 0.6335 - val_acc: 0.8041\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.2756 - acc: 0.8922 - val_loss: 0.6577 - val_acc: 0.8058\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 4s 114ms/step - loss: 0.2767 - acc: 0.8922 - val_loss: 0.6473 - val_acc: 0.8041\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 4s 118ms/step - loss: 0.2685 - acc: 0.8948 - val_loss: 0.6371 - val_acc: 0.8007\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 4s 114ms/step - loss: 0.2741 - acc: 0.8926 - val_loss: 0.6144 - val_acc: 0.7998\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.2712 - acc: 0.8924 - val_loss: 0.6297 - val_acc: 0.8041\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 4s 121ms/step - loss: 0.2605 - acc: 0.8952 - val_loss: 0.6876 - val_acc: 0.7998\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 5s 125ms/step - loss: 0.2610 - acc: 0.8956 - val_loss: 0.6837 - val_acc: 0.8071\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 4s 114ms/step - loss: 0.2594 - acc: 0.8961 - val_loss: 0.6934 - val_acc: 0.8037\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 4s 113ms/step - loss: 0.2670 - acc: 0.8954 - val_loss: 0.6792 - val_acc: 0.8041\n"
     ]
    }
   ],
   "source": [
    "hist_2 = lstm_mod2.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9143\n",
      "Testing Accuracy:  0.7968\n"
     ]
    }
   ],
   "source": [
    "# Find train and test accuracy\n",
    "loss, accuracy = lstm_mod2.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = lstm_mod2.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: LSTM Layer Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1576900   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 256)           365568    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,139,975\n",
      "Trainable params: 563,075\n",
      "Non-trainable params: 1,576,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model_3 = Sequential()\n",
    "model_3.add(embedding_layer)\n",
    "model_3.add(LSTM(256, \n",
    "               dropout = 0.2, \n",
    "               recurrent_dropout = 0.5,\n",
    "                 return_sequences = True))\n",
    "model_3.add(LSTM(128,\n",
    "                dropout = 0.2,\n",
    "                recurrent_dropout = 0.5))\n",
    "model_3.add(Dense(3, activation='softmax'))\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 30s 814ms/step - loss: 0.8122 - acc: 0.6498 - val_loss: 0.7434 - val_acc: 0.7192\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 29s 797ms/step - loss: 0.6764 - acc: 0.7265 - val_loss: 0.6523 - val_acc: 0.7362\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 30s 798ms/step - loss: 0.6228 - acc: 0.7429 - val_loss: 0.6058 - val_acc: 0.7601\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 30s 810ms/step - loss: 0.6093 - acc: 0.7513 - val_loss: 0.5967 - val_acc: 0.7563\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 0.5929 - acc: 0.7549 - val_loss: 0.5818 - val_acc: 0.7665\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 0.5781 - acc: 0.7641 - val_loss: 0.5538 - val_acc: 0.7729\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 30s 813ms/step - loss: 0.5644 - acc: 0.7686 - val_loss: 0.5597 - val_acc: 0.7717\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 0.5530 - acc: 0.7772 - val_loss: 0.5416 - val_acc: 0.7832\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 30s 823ms/step - loss: 0.5331 - acc: 0.7833 - val_loss: 0.5287 - val_acc: 0.7900\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 0.5160 - acc: 0.7924 - val_loss: 0.5381 - val_acc: 0.7845\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 31s 826ms/step - loss: 0.5148 - acc: 0.7926 - val_loss: 0.5365 - val_acc: 0.7793\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 31s 829ms/step - loss: 0.4974 - acc: 0.7968 - val_loss: 0.5345 - val_acc: 0.7798\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 30s 820ms/step - loss: 0.4853 - acc: 0.8056 - val_loss: 0.5114 - val_acc: 0.7998\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 30s 812ms/step - loss: 0.4775 - acc: 0.8079 - val_loss: 0.5067 - val_acc: 0.7994\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 0.4656 - acc: 0.8152 - val_loss: 0.5357 - val_acc: 0.7913\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 32s 876ms/step - loss: 0.4534 - acc: 0.8186 - val_loss: 0.5156 - val_acc: 0.7939\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 30s 812ms/step - loss: 0.4390 - acc: 0.8238 - val_loss: 0.5087 - val_acc: 0.7977\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 30s 816ms/step - loss: 0.4294 - acc: 0.8271 - val_loss: 0.5131 - val_acc: 0.8011\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 30s 809ms/step - loss: 0.4198 - acc: 0.8317 - val_loss: 0.5128 - val_acc: 0.7960\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 30s 820ms/step - loss: 0.4067 - acc: 0.8380 - val_loss: 0.5527 - val_acc: 0.7985\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 30s 810ms/step - loss: 0.3948 - acc: 0.8409 - val_loss: 0.5794 - val_acc: 0.7956\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 30s 813ms/step - loss: 0.3909 - acc: 0.8451 - val_loss: 0.5610 - val_acc: 0.8003\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 0.3812 - acc: 0.8528 - val_loss: 0.5458 - val_acc: 0.7853\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 31s 833ms/step - loss: 0.3700 - acc: 0.8528 - val_loss: 0.5825 - val_acc: 0.7866\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 30s 814ms/step - loss: 0.3643 - acc: 0.8567 - val_loss: 0.5469 - val_acc: 0.7951\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 31s 838ms/step - loss: 0.3507 - acc: 0.8600 - val_loss: 0.5816 - val_acc: 0.7985\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 30s 819ms/step - loss: 0.3492 - acc: 0.8601 - val_loss: 0.5522 - val_acc: 0.7806\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 0.3292 - acc: 0.8692 - val_loss: 0.5693 - val_acc: 0.7840\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 30s 814ms/step - loss: 0.3209 - acc: 0.8753 - val_loss: 0.5901 - val_acc: 0.7917\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 31s 825ms/step - loss: 0.3019 - acc: 0.8818 - val_loss: 0.5836 - val_acc: 0.7994\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 30s 815ms/step - loss: 0.2941 - acc: 0.8864 - val_loss: 0.6082 - val_acc: 0.7909\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 30s 811ms/step - loss: 0.2912 - acc: 0.8870 - val_loss: 0.6026 - val_acc: 0.7985\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 30s 815ms/step - loss: 0.2679 - acc: 0.8952 - val_loss: 0.5925 - val_acc: 0.7921\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 31s 829ms/step - loss: 0.2725 - acc: 0.8912 - val_loss: 0.5919 - val_acc: 0.8020\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 0.2614 - acc: 0.8990 - val_loss: 0.6707 - val_acc: 0.7939\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 31s 825ms/step - loss: 0.2500 - acc: 0.9024 - val_loss: 0.6476 - val_acc: 0.7917\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 30s 813ms/step - loss: 0.2370 - acc: 0.9061 - val_loss: 0.6695 - val_acc: 0.7926\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 30s 814ms/step - loss: 0.2343 - acc: 0.9116 - val_loss: 0.6692 - val_acc: 0.7951\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 30s 824ms/step - loss: 0.2072 - acc: 0.9214 - val_loss: 0.7075 - val_acc: 0.7866\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 30s 806ms/step - loss: 0.2149 - acc: 0.9192 - val_loss: 0.6778 - val_acc: 0.7990\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 30s 812ms/step - loss: 0.2073 - acc: 0.9189 - val_loss: 0.6929 - val_acc: 0.7896\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 31s 825ms/step - loss: 0.2037 - acc: 0.9236 - val_loss: 0.7215 - val_acc: 0.7981\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 30s 815ms/step - loss: 0.1854 - acc: 0.9286 - val_loss: 0.7476 - val_acc: 0.7947\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 30s 809ms/step - loss: 0.1831 - acc: 0.9301 - val_loss: 0.7679 - val_acc: 0.7960\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 30s 814ms/step - loss: 0.1861 - acc: 0.9308 - val_loss: 0.7711 - val_acc: 0.7985\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 30s 817ms/step - loss: 0.1740 - acc: 0.9343 - val_loss: 0.7252 - val_acc: 0.7849\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 0.1644 - acc: 0.9387 - val_loss: 0.7684 - val_acc: 0.7904\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 0.1674 - acc: 0.9378 - val_loss: 0.7886 - val_acc: 0.7836\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 30s 802ms/step - loss: 0.1567 - acc: 0.9405 - val_loss: 0.7763 - val_acc: 0.8054\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 30s 811ms/step - loss: 0.1509 - acc: 0.9452 - val_loss: 0.7732 - val_acc: 0.7921\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 0.1557 - acc: 0.9419 - val_loss: 0.7729 - val_acc: 0.7909\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 30s 801ms/step - loss: 0.1494 - acc: 0.9447 - val_loss: 0.7840 - val_acc: 0.7883\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 30s 810ms/step - loss: 0.1356 - acc: 0.9493 - val_loss: 0.7915 - val_acc: 0.7947\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 30s 800ms/step - loss: 0.1282 - acc: 0.9540 - val_loss: 0.8463 - val_acc: 0.7921\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 0.1280 - acc: 0.9533 - val_loss: 0.8464 - val_acc: 0.7810\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 30s 801ms/step - loss: 0.1231 - acc: 0.9535 - val_loss: 0.9075 - val_acc: 0.7887\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 30s 810ms/step - loss: 0.1248 - acc: 0.9525 - val_loss: 0.8738 - val_acc: 0.7738\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 30s 804ms/step - loss: 0.1267 - acc: 0.9522 - val_loss: 0.9019 - val_acc: 0.7917\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 30s 809ms/step - loss: 0.1115 - acc: 0.9592 - val_loss: 0.9402 - val_acc: 0.7793\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 30s 809ms/step - loss: 0.1132 - acc: 0.9600 - val_loss: 0.8662 - val_acc: 0.7883\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 0.1161 - acc: 0.9587 - val_loss: 0.8826 - val_acc: 0.7904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "37/37 [==============================] - 30s 799ms/step - loss: 0.1052 - acc: 0.9622 - val_loss: 0.9430 - val_acc: 0.7832\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 0.0942 - acc: 0.9657 - val_loss: 0.9389 - val_acc: 0.7909\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 0.0972 - acc: 0.9640 - val_loss: 0.9414 - val_acc: 0.7793\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 29s 796ms/step - loss: 0.0973 - acc: 0.9634 - val_loss: 0.9209 - val_acc: 0.7751\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 30s 799ms/step - loss: 0.0969 - acc: 0.9652 - val_loss: 0.9106 - val_acc: 0.7879\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 30s 802ms/step - loss: 0.0957 - acc: 0.9657 - val_loss: 0.9123 - val_acc: 0.7819\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 30s 799ms/step - loss: 0.0928 - acc: 0.9674 - val_loss: 0.9569 - val_acc: 0.7828\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 30s 816ms/step - loss: 0.0863 - acc: 0.9700 - val_loss: 1.0047 - val_acc: 0.8003\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 0.1057 - acc: 0.9617 - val_loss: 0.9295 - val_acc: 0.7956\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 30s 804ms/step - loss: 0.0865 - acc: 0.9689 - val_loss: 0.9717 - val_acc: 0.7943\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 30s 807ms/step - loss: 0.0941 - acc: 0.9672 - val_loss: 0.9307 - val_acc: 0.7921\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 0.0917 - acc: 0.9682 - val_loss: 0.9475 - val_acc: 0.7849\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 0.0859 - acc: 0.9696 - val_loss: 0.9890 - val_acc: 0.7973\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 30s 802ms/step - loss: 0.0797 - acc: 0.9703 - val_loss: 0.9701 - val_acc: 0.7875\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 30s 798ms/step - loss: 0.0837 - acc: 0.9690 - val_loss: 1.0075 - val_acc: 0.7840\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 30s 802ms/step - loss: 0.0765 - acc: 0.9738 - val_loss: 0.9879 - val_acc: 0.7823\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 29s 793ms/step - loss: 0.0660 - acc: 0.9779 - val_loss: 1.0598 - val_acc: 0.7892\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 30s 799ms/step - loss: 0.0793 - acc: 0.9724 - val_loss: 0.9262 - val_acc: 0.7810\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 30s 804ms/step - loss: 0.0693 - acc: 0.9761 - val_loss: 1.0095 - val_acc: 0.7896\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 30s 810ms/step - loss: 0.0732 - acc: 0.9726 - val_loss: 0.9587 - val_acc: 0.7887\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 30s 813ms/step - loss: 0.0685 - acc: 0.9763 - val_loss: 1.0025 - val_acc: 0.7981\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 30s 800ms/step - loss: 0.0653 - acc: 0.9775 - val_loss: 1.1295 - val_acc: 0.7657\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 0.0893 - acc: 0.9682 - val_loss: 0.9599 - val_acc: 0.7917\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 31s 826ms/step - loss: 0.0618 - acc: 0.9777 - val_loss: 1.0563 - val_acc: 0.7819\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 834s 23s/step - loss: 0.0602 - acc: 0.9793 - val_loss: 1.0709 - val_acc: 0.7934\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.0619 - acc: 0.9780 - val_loss: 1.0639 - val_acc: 0.7926\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.0654 - acc: 0.9767 - val_loss: 1.0497 - val_acc: 0.7798\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 37s 994ms/step - loss: 0.0629 - acc: 0.9784 - val_loss: 1.0571 - val_acc: 0.7909\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 33s 893ms/step - loss: 0.0537 - acc: 0.9827 - val_loss: 1.0776 - val_acc: 0.7832\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 31s 830ms/step - loss: 0.0671 - acc: 0.9773 - val_loss: 1.0325 - val_acc: 0.7930\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 31s 833ms/step - loss: 0.0612 - acc: 0.9783 - val_loss: 1.0375 - val_acc: 0.7990\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 31s 838ms/step - loss: 0.0540 - acc: 0.9814 - val_loss: 1.0929 - val_acc: 0.7921\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 31s 848ms/step - loss: 0.0540 - acc: 0.9826 - val_loss: 1.1159 - val_acc: 0.7998\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 30s 823ms/step - loss: 0.0570 - acc: 0.9800 - val_loss: 1.1899 - val_acc: 0.8062\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 31s 827ms/step - loss: 0.0586 - acc: 0.9799 - val_loss: 1.1670 - val_acc: 0.7921\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 33s 901ms/step - loss: 0.0513 - acc: 0.9828 - val_loss: 1.1293 - val_acc: 0.7909\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 30s 818ms/step - loss: 0.0604 - acc: 0.9779 - val_loss: 1.0781 - val_acc: 0.7926\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 30s 810ms/step - loss: 0.0539 - acc: 0.9806 - val_loss: 1.1312 - val_acc: 0.7977\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 0.0534 - acc: 0.9821 - val_loss: 1.0266 - val_acc: 0.7981\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9557\n",
      "Testing Accuracy:  0.7818\n"
     ]
    }
   ],
   "source": [
    "# Find train and test accuracy\n",
    "loss, accuracy = model_3.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_3.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: GRU Layer Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1576900   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 30, 256)           274944    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               148224    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,000,455\n",
      "Trainable params: 423,555\n",
      "Non-trainable params: 1,576,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GRU Model 2:\n",
    "model_4 = Sequential()\n",
    "model_4.add(embedding_layer)\n",
    "model_4.add(GRU(256, \n",
    "               dropout = 0.2, \n",
    "               recurrent_dropout = 0.5,\n",
    "                 return_sequences = True))\n",
    "model_4.add(GRU(128,\n",
    "                dropout = 0.2,\n",
    "                recurrent_dropout = 0.5))\n",
    "model_4.add(Dense(3, activation='softmax'))\n",
    "model_4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 24s 642ms/step - loss: 0.8663 - acc: 0.6233 - val_loss: 0.7675 - val_acc: 0.6748\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 23s 624ms/step - loss: 0.7340 - acc: 0.6895 - val_loss: 0.7405 - val_acc: 0.6906\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 24s 646ms/step - loss: 0.6866 - acc: 0.7142 - val_loss: 0.6308 - val_acc: 0.7465\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 25s 662ms/step - loss: 0.6264 - acc: 0.7421 - val_loss: 0.6057 - val_acc: 0.7584\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 24s 657ms/step - loss: 0.5893 - acc: 0.7570 - val_loss: 0.5651 - val_acc: 0.7776\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 24s 656ms/step - loss: 0.5721 - acc: 0.7677 - val_loss: 0.5483 - val_acc: 0.7700\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 24s 657ms/step - loss: 0.5625 - acc: 0.7702 - val_loss: 0.5379 - val_acc: 0.7857\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 24s 658ms/step - loss: 0.5369 - acc: 0.7815 - val_loss: 0.5313 - val_acc: 0.7968\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 24s 642ms/step - loss: 0.5300 - acc: 0.7876 - val_loss: 0.5402 - val_acc: 0.7870\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 25s 670ms/step - loss: 0.5281 - acc: 0.7894 - val_loss: 0.5262 - val_acc: 0.7909\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 24s 658ms/step - loss: 0.5101 - acc: 0.7965 - val_loss: 0.5118 - val_acc: 0.8007\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 23s 624ms/step - loss: 0.4962 - acc: 0.7999 - val_loss: 0.5107 - val_acc: 0.8067\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 24s 639ms/step - loss: 0.4868 - acc: 0.8080 - val_loss: 0.5101 - val_acc: 0.8037\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 23s 620ms/step - loss: 0.4681 - acc: 0.8113 - val_loss: 0.5119 - val_acc: 0.8054\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 24s 644ms/step - loss: 0.4678 - acc: 0.8157 - val_loss: 0.5001 - val_acc: 0.8058\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 23s 631ms/step - loss: 0.4607 - acc: 0.8179 - val_loss: 0.5018 - val_acc: 0.8041\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 23s 622ms/step - loss: 0.4482 - acc: 0.8228 - val_loss: 0.5162 - val_acc: 0.8062\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 24s 636ms/step - loss: 0.4282 - acc: 0.8330 - val_loss: 0.4987 - val_acc: 0.8131\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 23s 621ms/step - loss: 0.4346 - acc: 0.8272 - val_loss: 0.5517 - val_acc: 0.7968\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 23s 624ms/step - loss: 0.4381 - acc: 0.8260 - val_loss: 0.5155 - val_acc: 0.8092\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 23s 622ms/step - loss: 0.4027 - acc: 0.8395 - val_loss: 0.5010 - val_acc: 0.8152\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 23s 622ms/step - loss: 0.4000 - acc: 0.8443 - val_loss: 0.4828 - val_acc: 0.8190\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 23s 613ms/step - loss: 0.3882 - acc: 0.8493 - val_loss: 0.4890 - val_acc: 0.8186\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 24s 641ms/step - loss: 0.3888 - acc: 0.8479 - val_loss: 0.5022 - val_acc: 0.8135\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 23s 614ms/step - loss: 0.3591 - acc: 0.8591 - val_loss: 0.5009 - val_acc: 0.8178\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 23s 628ms/step - loss: 0.3604 - acc: 0.8544 - val_loss: 0.5224 - val_acc: 0.8160\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 23s 616ms/step - loss: 0.3578 - acc: 0.8631 - val_loss: 0.4973 - val_acc: 0.8084\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 23s 633ms/step - loss: 0.3444 - acc: 0.8649 - val_loss: 0.5174 - val_acc: 0.8109\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 23s 614ms/step - loss: 0.3270 - acc: 0.8744 - val_loss: 0.5165 - val_acc: 0.8114\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 23s 624ms/step - loss: 0.3175 - acc: 0.8778 - val_loss: 0.5287 - val_acc: 0.8152\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 23s 621ms/step - loss: 0.3064 - acc: 0.8797 - val_loss: 0.5392 - val_acc: 0.7951\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 24s 636ms/step - loss: 0.3181 - acc: 0.8767 - val_loss: 0.5336 - val_acc: 0.8122\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 23s 616ms/step - loss: 0.3006 - acc: 0.8848 - val_loss: 0.5614 - val_acc: 0.8088\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 23s 618ms/step - loss: 0.2809 - acc: 0.8957 - val_loss: 0.5428 - val_acc: 0.7960\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 23s 610ms/step - loss: 0.2726 - acc: 0.8997 - val_loss: 0.5775 - val_acc: 0.8041\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 23s 618ms/step - loss: 0.2587 - acc: 0.9002 - val_loss: 0.5980 - val_acc: 0.8024\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 23s 609ms/step - loss: 0.2576 - acc: 0.9006 - val_loss: 0.5733 - val_acc: 0.8037\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 25s 687ms/step - loss: 0.2604 - acc: 0.9032 - val_loss: 0.5453 - val_acc: 0.8020\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 24s 650ms/step - loss: 0.2437 - acc: 0.9059 - val_loss: 0.6075 - val_acc: 0.8011\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 26s 710ms/step - loss: 0.2332 - acc: 0.9133 - val_loss: 0.5949 - val_acc: 0.7951\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 27s 741ms/step - loss: 0.2261 - acc: 0.9141 - val_loss: 0.6164 - val_acc: 0.8088\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 35s 954ms/step - loss: 0.2265 - acc: 0.9111 - val_loss: 0.6290 - val_acc: 0.8088\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 28s 760ms/step - loss: 0.2197 - acc: 0.9203 - val_loss: 0.5920 - val_acc: 0.8015\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 29s 772ms/step - loss: 0.2090 - acc: 0.9206 - val_loss: 0.6474 - val_acc: 0.8062\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 28s 749ms/step - loss: 0.2005 - acc: 0.9256 - val_loss: 0.5995 - val_acc: 0.8105\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 29s 792ms/step - loss: 0.1993 - acc: 0.9226 - val_loss: 0.6330 - val_acc: 0.7981\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 30s 806ms/step - loss: 0.2098 - acc: 0.9205 - val_loss: 0.6045 - val_acc: 0.7990\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 33s 895ms/step - loss: 0.1869 - acc: 0.9294 - val_loss: 0.6664 - val_acc: 0.8071\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 29s 775ms/step - loss: 0.1723 - acc: 0.9349 - val_loss: 0.7093 - val_acc: 0.7917\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 31s 826ms/step - loss: 0.1785 - acc: 0.9317 - val_loss: 0.6782 - val_acc: 0.8075\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 37s 996ms/step - loss: 0.1688 - acc: 0.9371 - val_loss: 0.6888 - val_acc: 0.8050\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 33s 903ms/step - loss: 0.1645 - acc: 0.9394 - val_loss: 0.7094 - val_acc: 0.7981\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 35s 940ms/step - loss: 0.1589 - acc: 0.9428 - val_loss: 0.7293 - val_acc: 0.8041\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 37s 1s/step - loss: 0.1565 - acc: 0.9409 - val_loss: 0.7166 - val_acc: 0.8011\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 31s 830ms/step - loss: 0.1430 - acc: 0.9479 - val_loss: 0.7578 - val_acc: 0.7973\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 28s 743ms/step - loss: 0.1511 - acc: 0.9445 - val_loss: 0.7273 - val_acc: 0.7849\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 31s 835ms/step - loss: 0.1416 - acc: 0.9489 - val_loss: 0.7721 - val_acc: 0.7926\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 28s 764ms/step - loss: 0.1437 - acc: 0.9465 - val_loss: 0.7319 - val_acc: 0.8020\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 29s 771ms/step - loss: 0.1285 - acc: 0.9518 - val_loss: 0.7678 - val_acc: 0.8011\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 34s 906ms/step - loss: 0.1261 - acc: 0.9542 - val_loss: 0.8063 - val_acc: 0.8028\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 35s 959ms/step - loss: 0.1246 - acc: 0.9561 - val_loss: 0.8080 - val_acc: 0.7956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "37/37 [==============================] - 33s 899ms/step - loss: 0.1257 - acc: 0.9530 - val_loss: 0.8600 - val_acc: 0.7960\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 32s 855ms/step - loss: 0.1210 - acc: 0.9546 - val_loss: 0.7951 - val_acc: 0.7934\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 28s 767ms/step - loss: 0.1232 - acc: 0.9545 - val_loss: 0.8142 - val_acc: 0.7939\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 25s 689ms/step - loss: 0.1169 - acc: 0.9582 - val_loss: 0.8410 - val_acc: 0.7917\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 25s 669ms/step - loss: 0.1118 - acc: 0.9585 - val_loss: 0.8066 - val_acc: 0.8024\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 24s 640ms/step - loss: 0.1063 - acc: 0.9603 - val_loss: 0.8859 - val_acc: 0.7973\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 24s 659ms/step - loss: 0.1080 - acc: 0.9582 - val_loss: 0.8202 - val_acc: 0.8015\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 26s 697ms/step - loss: 0.1122 - acc: 0.9576 - val_loss: 0.8793 - val_acc: 0.8020\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 30s 823ms/step - loss: 0.1088 - acc: 0.9617 - val_loss: 0.8690 - val_acc: 0.8079\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 27s 743ms/step - loss: 0.0988 - acc: 0.9623 - val_loss: 0.8687 - val_acc: 0.7994\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 25s 682ms/step - loss: 0.0960 - acc: 0.9676 - val_loss: 0.8627 - val_acc: 0.7960\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 25s 664ms/step - loss: 0.0914 - acc: 0.9657 - val_loss: 0.9133 - val_acc: 0.7981\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 24s 653ms/step - loss: 0.0944 - acc: 0.9645 - val_loss: 0.9272 - val_acc: 0.7930\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 27s 730ms/step - loss: 0.1007 - acc: 0.9609 - val_loss: 0.8999 - val_acc: 0.7930\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 29s 772ms/step - loss: 0.0854 - acc: 0.9702 - val_loss: 0.9325 - val_acc: 0.8020\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 25s 685ms/step - loss: 0.0896 - acc: 0.9664 - val_loss: 0.9428 - val_acc: 0.7977\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 26s 696ms/step - loss: 0.0876 - acc: 0.9695 - val_loss: 0.9071 - val_acc: 0.7977\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 25s 687ms/step - loss: 0.0864 - acc: 0.9676 - val_loss: 0.9152 - val_acc: 0.8011\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 25s 674ms/step - loss: 0.0811 - acc: 0.9704 - val_loss: 0.8879 - val_acc: 0.8020\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 26s 695ms/step - loss: 0.0811 - acc: 0.9697 - val_loss: 0.9625 - val_acc: 0.8041\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 25s 683ms/step - loss: 0.0811 - acc: 0.9714 - val_loss: 0.9333 - val_acc: 0.8007\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 26s 699ms/step - loss: 0.0842 - acc: 0.9701 - val_loss: 0.9779 - val_acc: 0.8058\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 29s 786ms/step - loss: 0.0815 - acc: 0.9697 - val_loss: 0.9232 - val_acc: 0.7973\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 28s 745ms/step - loss: 0.0739 - acc: 0.9731 - val_loss: 0.9745 - val_acc: 0.7977\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 25s 682ms/step - loss: 0.0722 - acc: 0.9742 - val_loss: 0.9709 - val_acc: 0.7981\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 28s 751ms/step - loss: 0.0786 - acc: 0.9716 - val_loss: 0.9605 - val_acc: 0.8011\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 24s 652ms/step - loss: 0.0777 - acc: 0.9710 - val_loss: 0.9299 - val_acc: 0.8028\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 23s 624ms/step - loss: 0.0741 - acc: 0.9747 - val_loss: 0.9863 - val_acc: 0.8041\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 23s 632ms/step - loss: 0.0714 - acc: 0.9744 - val_loss: 0.9654 - val_acc: 0.8007\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 23s 621ms/step - loss: 0.0738 - acc: 0.9740 - val_loss: 0.9647 - val_acc: 0.8007\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 23s 621ms/step - loss: 0.0677 - acc: 0.9769 - val_loss: 0.9700 - val_acc: 0.7964\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 22s 604ms/step - loss: 0.0664 - acc: 0.9766 - val_loss: 1.0231 - val_acc: 0.7828\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 24s 637ms/step - loss: 0.0600 - acc: 0.9790 - val_loss: 1.0289 - val_acc: 0.7998\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 22s 603ms/step - loss: 0.0659 - acc: 0.9767 - val_loss: 1.0224 - val_acc: 0.7947\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 23s 614ms/step - loss: 0.0650 - acc: 0.9778 - val_loss: 1.0048 - val_acc: 0.7968\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 23s 609ms/step - loss: 0.0722 - acc: 0.9743 - val_loss: 1.0094 - val_acc: 0.7956\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 24s 636ms/step - loss: 0.0629 - acc: 0.9765 - val_loss: 1.0049 - val_acc: 0.7981\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 23s 617ms/step - loss: 0.0621 - acc: 0.9791 - val_loss: 1.0274 - val_acc: 0.7879\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 23s 625ms/step - loss: 0.0590 - acc: 0.9791 - val_loss: 0.9915 - val_acc: 0.7892\n"
     ]
    }
   ],
   "source": [
    "history_4 = model_4.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9544\n",
      "Testing Accuracy:  0.7865\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_4.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_4.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Reduced GRU with More Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1576900   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 30, 64)            31872     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 32)                9408      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 1,618,279\n",
      "Trainable params: 41,379\n",
      "Non-trainable params: 1,576,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(embedding_layer)\n",
    "model_5.add(GRU(64, \n",
    "               dropout = 0.3, \n",
    "               recurrent_dropout = 0.5,\n",
    "                 return_sequences = True))\n",
    "model_5.add(GRU(32,\n",
    "                dropout = 0.2,\n",
    "                recurrent_dropout = 0.5))\n",
    "model_5.add(Dense(3, activation='softmax'))\n",
    "model_5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 6s 175ms/step - loss: 0.9157 - acc: 0.6155 - val_loss: 0.8583 - val_acc: 0.6176\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 6s 156ms/step - loss: 0.8469 - acc: 0.6283 - val_loss: 0.8330 - val_acc: 0.6453\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 5s 146ms/step - loss: 0.8045 - acc: 0.6592 - val_loss: 0.8107 - val_acc: 0.6662\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 6s 174ms/step - loss: 0.7450 - acc: 0.6734 - val_loss: 0.7211 - val_acc: 0.6987\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 7s 186ms/step - loss: 0.7025 - acc: 0.7021 - val_loss: 0.6612 - val_acc: 0.7264\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.6744 - acc: 0.7166 - val_loss: 0.6402 - val_acc: 0.7358\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.6529 - acc: 0.7273 - val_loss: 0.6307 - val_acc: 0.7499\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 0.6312 - acc: 0.7376 - val_loss: 0.6078 - val_acc: 0.7610\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 7s 177ms/step - loss: 0.6118 - acc: 0.7482 - val_loss: 0.5702 - val_acc: 0.7717\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.5873 - acc: 0.7620 - val_loss: 0.5482 - val_acc: 0.7836\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.5710 - acc: 0.7686 - val_loss: 0.5335 - val_acc: 0.7862\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.5597 - acc: 0.7753 - val_loss: 0.5321 - val_acc: 0.7896\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 0.5525 - acc: 0.7783 - val_loss: 0.5246 - val_acc: 0.7943\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.5412 - acc: 0.7787 - val_loss: 0.5202 - val_acc: 0.8007\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 6s 168ms/step - loss: 0.5381 - acc: 0.7827 - val_loss: 0.5221 - val_acc: 0.7900\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 6s 166ms/step - loss: 0.5305 - acc: 0.7898 - val_loss: 0.5287 - val_acc: 0.7981\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 7s 186ms/step - loss: 0.5300 - acc: 0.7840 - val_loss: 0.5134 - val_acc: 0.8054\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 6s 172ms/step - loss: 0.5136 - acc: 0.7954 - val_loss: 0.5043 - val_acc: 0.8071\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 7s 180ms/step - loss: 0.5094 - acc: 0.7935 - val_loss: 0.5006 - val_acc: 0.8165\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 7s 178ms/step - loss: 0.5149 - acc: 0.7934 - val_loss: 0.5060 - val_acc: 0.8045\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 6s 156ms/step - loss: 0.5009 - acc: 0.7998 - val_loss: 0.4945 - val_acc: 0.8135\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 6s 168ms/step - loss: 0.4947 - acc: 0.8029 - val_loss: 0.5038 - val_acc: 0.8109\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 6s 154ms/step - loss: 0.4949 - acc: 0.8032 - val_loss: 0.4937 - val_acc: 0.8109\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.4820 - acc: 0.8110 - val_loss: 0.4904 - val_acc: 0.8148\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 6s 168ms/step - loss: 0.4841 - acc: 0.8080 - val_loss: 0.4965 - val_acc: 0.8178\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 6s 167ms/step - loss: 0.4830 - acc: 0.8067 - val_loss: 0.4924 - val_acc: 0.8152\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 7s 188ms/step - loss: 0.4744 - acc: 0.8113 - val_loss: 0.4969 - val_acc: 0.8178\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.4732 - acc: 0.8130 - val_loss: 0.4907 - val_acc: 0.8143\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.4715 - acc: 0.8102 - val_loss: 0.4838 - val_acc: 0.8190\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.4742 - acc: 0.8105 - val_loss: 0.4896 - val_acc: 0.8195\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.4632 - acc: 0.8152 - val_loss: 0.4973 - val_acc: 0.8122\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 6s 165ms/step - loss: 0.4633 - acc: 0.8145 - val_loss: 0.5005 - val_acc: 0.8126\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 6s 156ms/step - loss: 0.4617 - acc: 0.8152 - val_loss: 0.4850 - val_acc: 0.8186\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 6s 159ms/step - loss: 0.4521 - acc: 0.8189 - val_loss: 0.4798 - val_acc: 0.8212\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 6s 164ms/step - loss: 0.4536 - acc: 0.8197 - val_loss: 0.4858 - val_acc: 0.8173\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 6s 151ms/step - loss: 0.4476 - acc: 0.8218 - val_loss: 0.4817 - val_acc: 0.8190\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.4503 - acc: 0.8236 - val_loss: 0.4933 - val_acc: 0.8169\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 6s 165ms/step - loss: 0.4449 - acc: 0.8236 - val_loss: 0.4941 - val_acc: 0.8122\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 6s 160ms/step - loss: 0.4405 - acc: 0.8271 - val_loss: 0.4758 - val_acc: 0.8207\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 6s 174ms/step - loss: 0.4377 - acc: 0.8261 - val_loss: 0.4901 - val_acc: 0.8199\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 6s 156ms/step - loss: 0.4387 - acc: 0.8258 - val_loss: 0.4883 - val_acc: 0.8203\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 6s 166ms/step - loss: 0.4360 - acc: 0.8256 - val_loss: 0.4814 - val_acc: 0.8199\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.4277 - acc: 0.8317 - val_loss: 0.4763 - val_acc: 0.8259\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.4261 - acc: 0.8325 - val_loss: 0.4732 - val_acc: 0.8263\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.4288 - acc: 0.8277 - val_loss: 0.4856 - val_acc: 0.8182\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.4275 - acc: 0.8272 - val_loss: 0.4768 - val_acc: 0.8233\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.4211 - acc: 0.8369 - val_loss: 0.4771 - val_acc: 0.8242\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 7s 178ms/step - loss: 0.4156 - acc: 0.8368 - val_loss: 0.4761 - val_acc: 0.8242\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 6s 160ms/step - loss: 0.4107 - acc: 0.8364 - val_loss: 0.4812 - val_acc: 0.8250\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 6s 171ms/step - loss: 0.4167 - acc: 0.8370 - val_loss: 0.4739 - val_acc: 0.8237\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 6s 157ms/step - loss: 0.4079 - acc: 0.8398 - val_loss: 0.4847 - val_acc: 0.8203\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.4069 - acc: 0.8398 - val_loss: 0.4737 - val_acc: 0.8224\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 6s 165ms/step - loss: 0.4014 - acc: 0.8436 - val_loss: 0.4792 - val_acc: 0.8254\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 6s 149ms/step - loss: 0.4127 - acc: 0.8377 - val_loss: 0.4837 - val_acc: 0.8229\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 6s 159ms/step - loss: 0.4069 - acc: 0.8373 - val_loss: 0.4738 - val_acc: 0.8276\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.3978 - acc: 0.8451 - val_loss: 0.4778 - val_acc: 0.8199\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 6s 152ms/step - loss: 0.3942 - acc: 0.8456 - val_loss: 0.4800 - val_acc: 0.8242\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 6s 168ms/step - loss: 0.3950 - acc: 0.8440 - val_loss: 0.4803 - val_acc: 0.8220\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 0.3940 - acc: 0.8461 - val_loss: 0.4839 - val_acc: 0.8224\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 6s 157ms/step - loss: 0.3903 - acc: 0.8441 - val_loss: 0.4865 - val_acc: 0.8186\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.3932 - acc: 0.8475 - val_loss: 0.4792 - val_acc: 0.8199\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 6s 152ms/step - loss: 0.3824 - acc: 0.8514 - val_loss: 0.4869 - val_acc: 0.8216\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 6s 164ms/step - loss: 0.3852 - acc: 0.8476 - val_loss: 0.4824 - val_acc: 0.8224\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.3789 - acc: 0.8539 - val_loss: 0.4763 - val_acc: 0.8139\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 6s 159ms/step - loss: 0.3824 - acc: 0.8498 - val_loss: 0.4795 - val_acc: 0.8195\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 6s 168ms/step - loss: 0.3800 - acc: 0.8545 - val_loss: 0.4799 - val_acc: 0.8233\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 6s 157ms/step - loss: 0.3826 - acc: 0.8500 - val_loss: 0.4805 - val_acc: 0.8212\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.3740 - acc: 0.8545 - val_loss: 0.4834 - val_acc: 0.8220\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.3790 - acc: 0.8574 - val_loss: 0.4820 - val_acc: 0.8190\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.3793 - acc: 0.8495 - val_loss: 0.4905 - val_acc: 0.8280\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.3768 - acc: 0.8513 - val_loss: 0.4802 - val_acc: 0.8237\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.3719 - acc: 0.8540 - val_loss: 0.4934 - val_acc: 0.8186\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 6s 154ms/step - loss: 0.3733 - acc: 0.8560 - val_loss: 0.4824 - val_acc: 0.8203\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.3632 - acc: 0.8547 - val_loss: 0.4900 - val_acc: 0.8216\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.3699 - acc: 0.8548 - val_loss: 0.4916 - val_acc: 0.8233\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.3668 - acc: 0.8553 - val_loss: 0.4878 - val_acc: 0.8212\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.3558 - acc: 0.8599 - val_loss: 0.5040 - val_acc: 0.8229\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 6s 150ms/step - loss: 0.3496 - acc: 0.8607 - val_loss: 0.4920 - val_acc: 0.8216\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.3554 - acc: 0.8600 - val_loss: 0.4878 - val_acc: 0.8199\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 0.3552 - acc: 0.8631 - val_loss: 0.4950 - val_acc: 0.8224\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 6s 166ms/step - loss: 0.3663 - acc: 0.8572 - val_loss: 0.5050 - val_acc: 0.8190\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 7s 179ms/step - loss: 0.3536 - acc: 0.8617 - val_loss: 0.5076 - val_acc: 0.8160\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 0.3515 - acc: 0.8649 - val_loss: 0.4923 - val_acc: 0.8229\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.3475 - acc: 0.8663 - val_loss: 0.4880 - val_acc: 0.8250\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.3470 - acc: 0.8641 - val_loss: 0.4906 - val_acc: 0.8229\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 6s 157ms/step - loss: 0.3487 - acc: 0.8659 - val_loss: 0.5154 - val_acc: 0.8160\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 6s 174ms/step - loss: 0.3478 - acc: 0.8606 - val_loss: 0.5024 - val_acc: 0.8207\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.3431 - acc: 0.8659 - val_loss: 0.5129 - val_acc: 0.8165\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 7s 190ms/step - loss: 0.3362 - acc: 0.8669 - val_loss: 0.5031 - val_acc: 0.8156\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 7s 191ms/step - loss: 0.3398 - acc: 0.8671 - val_loss: 0.5090 - val_acc: 0.8165\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 7s 185ms/step - loss: 0.3374 - acc: 0.8715 - val_loss: 0.5132 - val_acc: 0.8186\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 7s 190ms/step - loss: 0.3440 - acc: 0.8672 - val_loss: 0.4988 - val_acc: 0.8224\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 6s 173ms/step - loss: 0.3434 - acc: 0.8671 - val_loss: 0.5103 - val_acc: 0.8169\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 7s 198ms/step - loss: 0.3324 - acc: 0.8683 - val_loss: 0.5156 - val_acc: 0.8195\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 7s 179ms/step - loss: 0.3301 - acc: 0.8736 - val_loss: 0.5147 - val_acc: 0.8242\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 7s 185ms/step - loss: 0.3374 - acc: 0.8706 - val_loss: 0.5205 - val_acc: 0.8203\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 6s 175ms/step - loss: 0.3294 - acc: 0.8718 - val_loss: 0.5119 - val_acc: 0.8207\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 7s 182ms/step - loss: 0.3265 - acc: 0.8719 - val_loss: 0.5189 - val_acc: 0.8143\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 7s 194ms/step - loss: 0.3253 - acc: 0.8752 - val_loss: 0.5037 - val_acc: 0.8199\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 7s 176ms/step - loss: 0.3318 - acc: 0.8733 - val_loss: 0.5044 - val_acc: 0.8212\n"
     ]
    }
   ],
   "source": [
    "history_5 = model_5.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8964\n",
      "Testing Accuracy:  0.8081\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_5.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_5.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1576900   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,661,767\n",
      "Trainable params: 84,867\n",
      "Non-trainable params: 1,576,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "# Bidirectional RNNs\n",
    "model_6 = Sequential()\n",
    "model_6.add(embedding_layer)\n",
    "model_6.add(Bidirectional(LSTM(64,\n",
    "                              dropout=0.2,\n",
    "                              recurrent_dropout=0.5)))\n",
    "model_6.add(Dense(3,activation='softmax'))\n",
    "model_6.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 12s 317ms/step - loss: 0.8368 - acc: 0.6388 - val_loss: 0.7747 - val_acc: 0.6761\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 10s 284ms/step - loss: 0.6901 - acc: 0.7170 - val_loss: 0.6230 - val_acc: 0.7520\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.6207 - acc: 0.7423 - val_loss: 0.6097 - val_acc: 0.7601\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.5947 - acc: 0.7558 - val_loss: 0.5726 - val_acc: 0.7725\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.5759 - acc: 0.7605 - val_loss: 0.6434 - val_acc: 0.7537\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.5714 - acc: 0.7640 - val_loss: 0.5523 - val_acc: 0.7781\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 12s 316ms/step - loss: 0.5520 - acc: 0.7759 - val_loss: 0.5552 - val_acc: 0.7810\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 10s 275ms/step - loss: 0.5360 - acc: 0.7825 - val_loss: 0.5428 - val_acc: 0.7853\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 9s 257ms/step - loss: 0.5354 - acc: 0.7807 - val_loss: 0.5358 - val_acc: 0.7913\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.5248 - acc: 0.7861 - val_loss: 0.5295 - val_acc: 0.7917\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.5127 - acc: 0.7945 - val_loss: 0.5637 - val_acc: 0.7849\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 11s 292ms/step - loss: 0.4964 - acc: 0.8004 - val_loss: 0.5444 - val_acc: 0.7742\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 9s 246ms/step - loss: 0.5004 - acc: 0.8024 - val_loss: 0.5181 - val_acc: 0.7943\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.4869 - acc: 0.8085 - val_loss: 0.5203 - val_acc: 0.7947\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 9s 242ms/step - loss: 0.4794 - acc: 0.8098 - val_loss: 0.5220 - val_acc: 0.7947\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 8s 220ms/step - loss: 0.4713 - acc: 0.8087 - val_loss: 0.5372 - val_acc: 0.7947\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.4625 - acc: 0.8162 - val_loss: 0.5321 - val_acc: 0.7981\n",
      "Epoch 18/100\n",
      "27/37 [====================>.........] - ETA: 2s - loss: 0.4638 - acc: 0.8135"
     ]
    }
   ],
   "source": [
    "history_6 = model_6.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_6.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_6.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color=\"#004D7F\">Comparación de Modelos</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clave para una comparación equitativa de los algoritmos de ML es garantizar que cada algoritmo se evalúe de la misma manera en los mismos datos. Los algoritmos se comparan en un único conjunto de datos:\n",
    "* Logistic Regression.\n",
    "* Linear Discriminant Analysis.\n",
    "* k-Nearest Neighbors.\n",
    "* Classification and Regression Trees. \n",
    "* Naive Bayes.\n",
    "* Support Vector Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append((\"Simple LSTM Model with regularization, increase dimensionality\",  model_1.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"LSTM with regularization, reduce dimensionality\",  model_2.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"LSTM Layer Stacking\",  model_3.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"GRU Layer Stacking\", model_4.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"Reduced GRU with More Regularization\",  model_5.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"Bidirectional RNN\",  model_6.evaluate(X_train, y_train, verbose=False)))\n",
    "\n",
    "results=[]\n",
    "names=[]\n",
    "\n",
    "\n",
    "kfold=KFold(n_splits=10)\n",
    "for name, model in models: \n",
    "    loss, accuracy = model\n",
    "    results.append(accuracy)\n",
    "    names.append(name)\n",
    "    print(f\"Accuracy: {name}: {cv_results.mean()*100.0:,.2f}%  ({cv_results.std()*100.0:,.2f}) %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
