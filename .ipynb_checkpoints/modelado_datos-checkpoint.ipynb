{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<h2><font color=\"#004D7F\" size=6>Modelado de datos</font></h2>\n",
    "<h1></h1>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "<font color=\"#004D7F\" size=5>Curso: Inteligencia Artificial</font><br>\n",
    "<font color=\"#004D7F\" size=5>Docente: Juan Villegas Cubas</font><br>\n",
    "    <font color=\"#004D7F\" size=5>Alumno: Gonzalo LÃ³pez Guerrero</font><br>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Noviembre 2020</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /content/drive/MyDrive/IA_RNN/Data/Tweets.csv does not exist: '/content/drive/MyDrive/IA_RNN/Data/Tweets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1f2696310075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#PATH =\"../Data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/Tweets.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#rows x columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /content/drive/MyDrive/IA_RNN/Data/Tweets.csv does not exist: '/content/drive/MyDrive/IA_RNN/Data/Tweets.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import plotly \n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "#import twitter data\n",
    "\n",
    "PATH =\"/content/drive/MyDrive/IA_RNN/Data\"\n",
    "#PATH =\"../Data\"\n",
    "filename = PATH+'/Tweets.csv'\n",
    "dataset = pd.read_csv(filename)\n",
    "print(dataset.shape)#rows x columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cantidad de tweet por clase\n",
    "dataset['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir a entero los valores de las clases\n",
    "dataset['airline_sentiment'] = dataset['airline_sentiment'].replace('neutral', 1)\n",
    "dataset['airline_sentiment'] = dataset['airline_sentiment'].replace('negative', 0)\n",
    "dataset['airline_sentiment'] = dataset['airline_sentiment'].replace('positive', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividar los datos entre text y clase\n",
    "X = dataset['text'] # data\n",
    "y = dataset['airline_sentiment'] # labels\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "#class_weight = class_weight.compute_class_weight('balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Procesando Datos<7h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer  #reemplazar los caracteres especiales\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence #analiza la secuencia de los caracteres\n",
    "# Convertisa los datos en token\n",
    "# create tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(X)\n",
    "# Encuentra la cantidad de palabras Ãºnicas en los tweets\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# indexar las palabras (relacionar con su par entero)\n",
    "sequences = t.texts_to_sequences(X)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra el tweet con mayor numero de caracteres para ser tomado como referencias \n",
    "#al momento de vectorizar a las palabras\n",
    "def max_tweet():\n",
    "    for i in range(1, len(sequences)):\n",
    "        max_length = len(sequences[0])\n",
    "        if len(sequences[i]) > max_length:\n",
    "            max_length = len(sequences[i])\n",
    "    return max_length\n",
    "tweet_num = max_tweet()\n",
    "print(\"Mayor numero de caracteres en un tweet \" , tweet_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las palabras no encontradas en el tweet se llenan con ceros en el array\n",
    "# https://realpython.com/python-keras-text-classification/\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = tweet_num\n",
    "padded_X = pad_sequences(sequences, padding='post', maxlen=maxlen)\n",
    "valor_maximo =np.amax(padded_X) \n",
    "padded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir las etiquestas\n",
    "labels = to_categorical(np.asarray(y))\n",
    "labels\n",
    "# 1 => representa la clase que representa negativo / neutral / positivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "padded_Y = array[:,1] #array de clases\n",
    "padded_Y_test=padded_Y.astype('int')\n",
    "#padded_Y\n",
    "padded_X_test = (padded_X /valor_maximo) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_X, labels, test_size = 0.2, random_state = 0)\n",
    "# Size of train and test datasets\n",
    "print('X_train size:', X_train.shape)\n",
    "print('y_train size:', y_train.shape)\n",
    "print('X_test size:', X_test.shape)\n",
    "print('y_test size:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe se define como un âalgoritmo de aprendizaje no supervisado \n",
    "#para obtener representaciones vectoriales de palabrasâ. \n",
    "#Descargamos datos del sitio web vinculado y usamos especÃ­ficamente las incrustaciones\n",
    "#100-dimensionales de 400k palabras de Wikipedia en inglÃ©s en 2014. \n",
    "#Esto se representa en un archivo txt que debemos analizar para crear un\n",
    "#Ã­ndice que mapee las palabras a su representaciÃ³n vectorial.\n",
    "\n",
    "# 100 dimensional version (embedding dimension)\n",
    "\n",
    "#ayuda a en la decodificacion\n",
    "#https://stackoverflow.com/questions/9233027/unicodedecodeerror-charmap-codec-cant-decode-byte-x-in-position-y-character\n",
    "embeddings_index = dict()\n",
    "f = open(PATH+'/glove/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Vectores de palabras cargados: %s' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se Obtiene todas las palabras Ãºnicas en nuestro conjunto de entrenamiento: Ã­ndice de tokenizadores\n",
    "# Se encuentra el vector de peso correspondiente en la incrustaciÃ³n de GloVe\n",
    "\n",
    "# Se define el tamaÃ±o de la matriz de incrustaciÃ³n: nÃºmero de palabras Ãºnicas x incrustaciÃ³n dim (100)\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "\n",
    "# llenado de la matrix\n",
    "for word, i in t.word_index.items():  # dictionary\n",
    "    embedding_vector = embeddings_index.get(word) # obtiene un vector incrustado de palabra de GloVe\n",
    "    if embedding_vector is not None:\n",
    "        # se agrega a la matrix\n",
    "        embedding_matrix[i] = embedding_vector # cada fila de la matrix\n",
    "\n",
    "#print(embedding_matrix)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una capa de incrustaciÃ³n usando una matriz de incrustaciÃ³n\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# la entrada es vocab_size, la salida es 100\n",
    "# pesos de la matriz de incrustaciÃ³n, establezca entrenable = Falso || para q no se modifiquen los valores de Glove\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix],\n",
    "                           input_length = tweet_num, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Modelo LSTM simple con regularizaciÃ³n, aumento de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mod1 = Sequential()\n",
    "lstm_mod1.add(embedding_layer)\n",
    "lstm_mod1.add(LSTM(256, \n",
    "               dropout = 0.2,\n",
    "               recurrent_dropout = 0.5))\n",
    "lstm_mod1.add(Dense(3, activation='softmax'))\n",
    "lstm_mod1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "lstm_mod1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist_1 = lstm_mod1.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y test accuracy\n",
    "loss, accuracy = lstm_mod1.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = lstm_mod1.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train/test loss and accuracy\n",
    "acc = hist_1.history['acc']\n",
    "val_acc = hist_1.history['val_acc']\n",
    "loss = hist_1.history['loss']\n",
    "val_loss = hist_1.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "# Get predicted values\n",
    "y_pred = lstm_mod1.predict(X_test)  # outputs probabilities of each sentiment\n",
    "# Create empty numpy array to match length of training observations\n",
    "y_pred_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with highest probability\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    label_predict = np.argmax(y_pred[i]) # column with max probability\n",
    "    y_pred_array[i] = label_predict\n",
    "\n",
    "# convert to integers\n",
    "y_pred_array = y_pred_array.astype(int)\n",
    "# Convert y_test to 1d numpy array\n",
    "y_test_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with 1\n",
    "for i in range(0, y_test.shape[0]):\n",
    "    label_predict = np.argmax(y_test[i])\n",
    "    y_test_array[i] = label_predict\n",
    "\n",
    "y_test_array = y_test_array.astype(int)\n",
    "class_names = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: LSTM con regularizaciÃ³n, reducir dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mod2 = Sequential()\n",
    "lstm_mod2.add(embedding_layer)\n",
    "lstm_mod2.add(LSTM(64, \n",
    "               dropout = 0.2, \n",
    "               recurrent_dropout = 0.5))\n",
    "lstm_mod2.add(Dense(3, activation='softmax'))\n",
    "lstm_mod2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "lstm_mod2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_2 = lstm_mod2.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datis de entrenamiento y test\n",
    "loss, accuracy = lstm_mod2.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = lstm_mod2.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train/test loss and accuracy\n",
    "acc = hist_2.history['acc']\n",
    "val_acc = hist_2.history['val_acc']\n",
    "loss = hist_1.history['loss']\n",
    "val_loss = hist_2.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "# Get predicted values\n",
    "y_pred = lstm_mod2.predict(X_test)  # outputs probabilities of each sentiment\n",
    "# Create empty numpy array to match length of training observations\n",
    "y_pred_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with highest probability\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    label_predict = np.argmax(y_pred[i]) # column with max probability\n",
    "    y_pred_array[i] = label_predict\n",
    "\n",
    "# convert to integers\n",
    "y_pred_array = y_pred_array.astype(int)\n",
    "# Convert y_test to 1d numpy array\n",
    "y_test_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with 1\n",
    "for i in range(0, y_test.shape[0]):\n",
    "    label_predict = np.argmax(y_test[i])\n",
    "    y_test_array[i] = label_predict\n",
    "\n",
    "y_test_array = y_test_array.astype(int)\n",
    "class_names = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: Apilamiento de capas LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "model_3 = Sequential()\n",
    "model_3.add(embedding_layer)\n",
    "model_3.add(LSTM(256, \n",
    "               dropout = 0.2, \n",
    "               recurrent_dropout = 0.5,\n",
    "                 return_sequences = True))#solo aplicable a multicapas\n",
    "model_3.add(LSTM(128,\n",
    "                dropout = 0.2,\n",
    "                recurrent_dropout = 0.5))\n",
    "model_3.add(Dense(3, activation='softmax'))\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_3 = model_3.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_3.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_3.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train/test loss and accuracy\n",
    "acc = hist_3.history['acc']\n",
    "val_acc = hist_3.history['val_acc']\n",
    "loss = hist_1.history['loss']\n",
    "val_loss = hist_3.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "# Get predicted values\n",
    "y_pred = model_3.predict(X_test)  # outputs probabilities of each sentiment\n",
    "# Create empty numpy array to match length of training observations\n",
    "y_pred_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with highest probability\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    label_predict = np.argmax(y_pred[i]) # column with max probability\n",
    "    y_pred_array[i] = label_predict\n",
    "\n",
    "# convert to integers\n",
    "y_pred_array = y_pred_array.astype(int)\n",
    "# Convert y_test to 1d numpy array\n",
    "y_test_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with 1\n",
    "for i in range(0, y_test.shape[0]):\n",
    "    label_predict = np.argmax(y_test[i])\n",
    "    y_test_array[i] = label_predict\n",
    "\n",
    "y_test_array = y_test_array.astype(int)\n",
    "class_names = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 4: Apilamiento de capas GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model 2:\n",
    "model_4 = Sequential()\n",
    "model_4.add(embedding_layer)\n",
    "model_4.add(GRU(256, \n",
    "               dropout = 0.2, \n",
    "               recurrent_dropout = 0.5,\n",
    "                 return_sequences = True))\n",
    "model_4.add(GRU(128,\n",
    "                dropout = 0.2,\n",
    "                recurrent_dropout = 0.5))\n",
    "model_4.add(Dense(3, activation='softmax'))\n",
    "model_4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_4 = model_4.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=200, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_4.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_4.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train/test loss and accuracy\n",
    "acc = hist_4.history['acc']\n",
    "val_acc = hist_4.history['val_acc']\n",
    "loss = hist_1.history['loss']\n",
    "val_loss = hist_4.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bd50d84c500d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get predicted values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# outputs probabilities of each sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# Create empty numpy array to match length of training observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_pred_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_4' is not defined"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "# Get predicted values\n",
    "y_pred = model_4.predict(X_test)  # outputs probabilities of each sentiment\n",
    "# Create empty numpy array to match length of training observations\n",
    "y_pred_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with highest probability\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    label_predict = np.argmax(y_pred[i]) # column with max probability\n",
    "    y_pred_array[i] = label_predict\n",
    "\n",
    "# convert to integers\n",
    "y_pred_array = y_pred_array.astype(int)\n",
    "# Convert y_test to 1d numpy array\n",
    "y_test_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with 1\n",
    "for i in range(0, y_test.shape[0]):\n",
    "    label_predict = np.argmax(y_test[i])\n",
    "    y_test_array[i] = label_predict\n",
    "\n",
    "y_test_array = y_test_array.astype(int)\n",
    "class_names = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizar :Model 4:-Reduced GRU with More Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 100)           1561500   \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 30, 256)           274944    \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (None, 128)               148224    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,985,055\n",
      "Trainable params: 423,555\n",
      "Non-trainable params: 1,561,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(embedding_layer)\n",
    "model_5.add(GRU(256, \n",
    "               dropout = 0.3, \n",
    "               recurrent_dropout = 0.5,\n",
    "                 return_sequences = True))\n",
    "model_5.add(GRU(128,\n",
    "                dropout = 0.2,\n",
    "                recurrent_dropout = 0.5))\n",
    "model_5.add(Dense(3, activation='softmax'))\n",
    "model_5.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.8909 - acc: 0.6188 - val_loss: 0.8437 - val_acc: 0.6270\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.8306 - acc: 0.6308 - val_loss: 0.7773 - val_acc: 0.6638\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.7584 - acc: 0.6781 - val_loss: 0.7215 - val_acc: 0.6915\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 46s 1s/step - loss: 0.7192 - acc: 0.6968 - val_loss: 0.6689 - val_acc: 0.7174\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.7021 - acc: 0.7059 - val_loss: 0.6577 - val_acc: 0.7183\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.6782 - acc: 0.7180 - val_loss: 0.6431 - val_acc: 0.7326\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 48s 1s/step - loss: 0.6664 - acc: 0.7260 - val_loss: 0.6525 - val_acc: 0.7330\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 45s 1s/step - loss: 0.6487 - acc: 0.7360 - val_loss: 0.6149 - val_acc: 0.7443\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 46s 1s/step - loss: 0.6382 - acc: 0.7349 - val_loss: 0.5979 - val_acc: 0.7456\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.6280 - acc: 0.7415 - val_loss: 0.6046 - val_acc: 0.7499\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.6260 - acc: 0.7430 - val_loss: 0.5890 - val_acc: 0.7551\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.6096 - acc: 0.7462 - val_loss: 0.5716 - val_acc: 0.7616\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.6078 - acc: 0.7518 - val_loss: 0.5627 - val_acc: 0.7642\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.5947 - acc: 0.7537 - val_loss: 0.5614 - val_acc: 0.7668\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.5900 - acc: 0.7594 - val_loss: 0.5697 - val_acc: 0.7607\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.5871 - acc: 0.7585 - val_loss: 0.5551 - val_acc: 0.7724\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.5778 - acc: 0.7623 - val_loss: 0.5525 - val_acc: 0.7711\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 46s 1s/step - loss: 0.5811 - acc: 0.7649 - val_loss: 0.5589 - val_acc: 0.7672\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 44s 1s/step - loss: 0.5875 - acc: 0.7577 - val_loss: 0.5587 - val_acc: 0.7663\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 52s 1s/step - loss: 0.5695 - acc: 0.7697 - val_loss: 0.5452 - val_acc: 0.7763\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 47s 1s/step - loss: 0.5793 - acc: 0.7640 - val_loss: 0.5446 - val_acc: 0.7767\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.5682 - acc: 0.7668 - val_loss: 0.5439 - val_acc: 0.7759\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.5587 - acc: 0.7762 - val_loss: 0.5386 - val_acc: 0.7845\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.5627 - acc: 0.7702 - val_loss: 0.5404 - val_acc: 0.7806\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 49s 1s/step - loss: 0.5568 - acc: 0.7721 - val_loss: 0.5381 - val_acc: 0.7828\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 44s 1s/step - loss: 0.5529 - acc: 0.7743 - val_loss: 0.5343 - val_acc: 0.7797\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5492 - acc: 0.7770 - val_loss: 0.5337 - val_acc: 0.7802\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.5431 - acc: 0.7786 - val_loss: 0.5547 - val_acc: 0.7741\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 48s 1s/step - loss: 0.5456 - acc: 0.7778 - val_loss: 0.5562 - val_acc: 0.7737\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 50s 1s/step - loss: 0.5451 - acc: 0.7769 - val_loss: 0.5325 - val_acc: 0.7832\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5432 - acc: 0.7779 - val_loss: 0.5320 - val_acc: 0.7810\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5344 - acc: 0.7868 - val_loss: 0.5267 - val_acc: 0.7871\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5258 - acc: 0.7866 - val_loss: 0.5339 - val_acc: 0.7849\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.5348 - acc: 0.7791 - val_loss: 0.5230 - val_acc: 0.7875\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.5209 - acc: 0.7883 - val_loss: 0.5210 - val_acc: 0.7867\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 47s 1s/step - loss: 0.5231 - acc: 0.7887 - val_loss: 0.5474 - val_acc: 0.7819\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5239 - acc: 0.7850 - val_loss: 0.5262 - val_acc: 0.7906\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.5128 - acc: 0.7930 - val_loss: 0.5287 - val_acc: 0.7880\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5139 - acc: 0.7895 - val_loss: 0.5469 - val_acc: 0.7836\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 48s 1s/step - loss: 0.5214 - acc: 0.7897 - val_loss: 0.5177 - val_acc: 0.7884\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.5089 - acc: 0.7971 - val_loss: 0.5230 - val_acc: 0.7984\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5027 - acc: 0.7973 - val_loss: 0.5175 - val_acc: 0.8001\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.5002 - acc: 0.7989 - val_loss: 0.5160 - val_acc: 0.7945\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.5062 - acc: 0.7957 - val_loss: 0.5107 - val_acc: 0.7962\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.4939 - acc: 0.7998 - val_loss: 0.5153 - val_acc: 0.7910\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4962 - acc: 0.8003 - val_loss: 0.5253 - val_acc: 0.7845\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4918 - acc: 0.7987 - val_loss: 0.5180 - val_acc: 0.7958\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4857 - acc: 0.8072 - val_loss: 0.5079 - val_acc: 0.7945\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.4919 - acc: 0.7993 - val_loss: 0.5313 - val_acc: 0.7927\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.4833 - acc: 0.8085 - val_loss: 0.5121 - val_acc: 0.7927\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 44s 1s/step - loss: 0.4855 - acc: 0.8077 - val_loss: 0.5310 - val_acc: 0.7828\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4876 - acc: 0.8022 - val_loss: 0.5357 - val_acc: 0.7867\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 0.4831 - acc: 0.8116 - val_loss: 0.5087 - val_acc: 0.7949\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.4831 - acc: 0.8077 - val_loss: 0.5368 - val_acc: 0.7849\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.4892 - acc: 0.8062 - val_loss: 0.5079 - val_acc: 0.7949\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.4678 - acc: 0.8143 - val_loss: 0.5117 - val_acc: 0.7940\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 48s 1s/step - loss: 0.4671 - acc: 0.8151 - val_loss: 0.5092 - val_acc: 0.7901\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 47s 1s/step - loss: 0.4770 - acc: 0.8087 - val_loss: 0.5069 - val_acc: 0.7975\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 53s 1s/step - loss: 0.4678 - acc: 0.8095 - val_loss: 0.5174 - val_acc: 0.8040\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 47s 1s/step - loss: 0.4707 - acc: 0.8163 - val_loss: 0.5059 - val_acc: 0.7979\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4754 - acc: 0.8076 - val_loss: 0.5163 - val_acc: 0.7984\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4560 - acc: 0.8189 - val_loss: 0.5029 - val_acc: 0.8005\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.4586 - acc: 0.8231 - val_loss: 0.5220 - val_acc: 0.7945\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.4596 - acc: 0.8159 - val_loss: 0.5276 - val_acc: 0.7932\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.4695 - acc: 0.8131 - val_loss: 0.5289 - val_acc: 0.7836\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4531 - acc: 0.8189 - val_loss: 0.5004 - val_acc: 0.8061\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.4484 - acc: 0.8232 - val_loss: 0.5681 - val_acc: 0.7659\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.4590 - acc: 0.8145 - val_loss: 0.5248 - val_acc: 0.7966\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4563 - acc: 0.8159 - val_loss: 0.5208 - val_acc: 0.7932\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.4521 - acc: 0.8170 - val_loss: 0.5094 - val_acc: 0.7975\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4472 - acc: 0.8236 - val_loss: 0.5037 - val_acc: 0.8040\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4447 - acc: 0.8227 - val_loss: 0.5066 - val_acc: 0.8040\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.4483 - acc: 0.8218 - val_loss: 0.5079 - val_acc: 0.8018\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.4448 - acc: 0.8237 - val_loss: 0.5322 - val_acc: 0.7958\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4452 - acc: 0.8222 - val_loss: 0.5104 - val_acc: 0.8018\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4463 - acc: 0.8244 - val_loss: 0.5077 - val_acc: 0.8023\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.4463 - acc: 0.8206 - val_loss: 0.5269 - val_acc: 0.7901\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4457 - acc: 0.8183 - val_loss: 0.5179 - val_acc: 0.8035\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 46s 1s/step - loss: 0.4376 - acc: 0.8264 - val_loss: 0.4948 - val_acc: 0.8057\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4308 - acc: 0.8297 - val_loss: 0.5082 - val_acc: 0.7966\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4310 - acc: 0.8265 - val_loss: 0.5034 - val_acc: 0.8014\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4313 - acc: 0.8273 - val_loss: 0.5040 - val_acc: 0.7953\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.4201 - acc: 0.8298 - val_loss: 0.5067 - val_acc: 0.7988\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 51s 1s/step - loss: 0.4306 - acc: 0.8317 - val_loss: 0.5063 - val_acc: 0.8057\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4176 - acc: 0.8353 - val_loss: 0.4997 - val_acc: 0.8044\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4168 - acc: 0.8334 - val_loss: 0.5014 - val_acc: 0.8040\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.4228 - acc: 0.8346 - val_loss: 0.4955 - val_acc: 0.8066\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4174 - acc: 0.8348 - val_loss: 0.5227 - val_acc: 0.8035\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 37s 1s/step - loss: 0.4186 - acc: 0.8378 - val_loss: 0.5100 - val_acc: 0.8044\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 42s 1s/step - loss: 0.4187 - acc: 0.8339 - val_loss: 0.5137 - val_acc: 0.8031\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4161 - acc: 0.8348 - val_loss: 0.5056 - val_acc: 0.8087\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 39s 1s/step - loss: 0.4155 - acc: 0.8381 - val_loss: 0.5128 - val_acc: 0.7975\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4059 - acc: 0.8404 - val_loss: 0.5054 - val_acc: 0.8079\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 41s 1s/step - loss: 0.4140 - acc: 0.8343 - val_loss: 0.5147 - val_acc: 0.7880\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 40s 1s/step - loss: 0.4143 - acc: 0.8384 - val_loss: 0.5140 - val_acc: 0.8023\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4098 - acc: 0.8370 - val_loss: 0.5059 - val_acc: 0.8023\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4126 - acc: 0.8374 - val_loss: 0.5064 - val_acc: 0.8079\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4046 - acc: 0.8375 - val_loss: 0.5003 - val_acc: 0.7992\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 38s 1s/step - loss: 0.4118 - acc: 0.8383 - val_loss: 0.5030 - val_acc: 0.8023\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 37s 1s/step - loss: 0.4072 - acc: 0.8384 - val_loss: 0.5079 - val_acc: 0.8053\n"
     ]
    }
   ],
   "source": [
    "hist_5 = model_5.fit(X_train, y_train,\n",
    "                    validation_split = 0.2,\n",
    "                    epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8598\n",
      "Testing Accuracy:  0.8124\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_5.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model_5.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train/test loss and accuracy\n",
    "acc = hist_5.history['acc']\n",
    "val_acc = hist_5.history['val_acc']\n",
    "loss = hist_5.history['loss']\n",
    "val_loss = hist_5.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1650  127   62]\n",
      " [ 218  318   81]\n",
      " [  70   39  324]]\n",
      "Normalized confusion matrix\n",
      "[[0.9  0.07 0.03]\n",
      " [0.35 0.52 0.13]\n",
      " [0.16 0.09 0.75]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "# Get predicted values\n",
    "y_pred = model_5.predict(X_test)  # outputs probabilities of each sentiment\n",
    "# Create empty numpy array to match length of training observations\n",
    "y_pred_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with highest probability\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    label_predict = np.argmax(y_pred[i]) # column with max probability\n",
    "    y_pred_array[i] = label_predict\n",
    "\n",
    "# convert to integers\n",
    "y_pred_array = y_pred_array.astype(int)\n",
    "# Convert y_test to 1d numpy array\n",
    "y_test_array = np.zeros(X_test.shape[0])\n",
    "\n",
    "# Find class with 1\n",
    "for i in range(0, y_test.shape[0]):\n",
    "    label_predict = np.argmax(y_test[i])\n",
    "    y_test_array[i] = label_predict\n",
    "\n",
    "y_test_array = y_test_array.astype(int)\n",
    "class_names = np.array(['Negative', 'Neutral', 'Positive'])\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(y_test_array, y_pred_array, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color=\"#004D7F\">ComparaciÃ³n de Modelos</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clave para una comparaciÃ³n equitativa de los algoritmos de ML es garantizar que cada algoritmo se evalÃºe de la misma manera en los mismos datos. Los algoritmos se comparan en un Ãºnico conjunto de datos:\n",
    "* Logistic Regression.\n",
    "* Linear Discriminant Analysis.\n",
    "* k-Nearest Neighbors.\n",
    "* Classification and Regression Trees. \n",
    "* Naive Bayes.\n",
    "* Support Vector Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Modelo LSTM simple con regularizaciÃ³n, aumento de dimensionalidad: 95.40%\n",
      "Accuracy: LSTM con regularizaciÃ³n, reducir dimensionalidad: 90.51%\n",
      "Accuracy: Apilamiento de capas LSTM: 95.17%\n",
      "Accuracy: Apilamiento de capas GRU: 95.45%\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "models.append((\"Modelo LSTM simple con regularizaciÃ³n, aumento de dimensionalidad\",  \n",
    "               lstm_mod1.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"LSTM con regularizaciÃ³n, reducir dimensionalidad\",  \n",
    "               lstm_mod2.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"Apilamiento de capas LSTM\",  \n",
    "               model_3.evaluate(X_train, y_train, verbose=False)))\n",
    "models.append((\"Apilamiento de capas GRU\", \n",
    "               model_4.evaluate(X_train, y_train, verbose=False)))\n",
    "\n",
    "results=[]\n",
    "names=[]\n",
    "\n",
    "\n",
    "for name, model in models: \n",
    "    loss, accuracy = model\n",
    "    results.append(accuracy)\n",
    "    names.append(name)\n",
    "    \n",
    "    print(f\"Accuracy: {name}: {accuracy*100.0:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
